# Juicer configuration file
juicer:
    debug: true
    minion:
        terminate_after_run: false
        libprocess_port_range: [37100, 37199]
        # IP address that will be advertised to the outside world for communication to and from libprocess
        libprocess_advertise_ip: 127.0.0.1
        port_offset: 100
    servers:
        redis_url: redis://redis:6379
    services:
        tahiti:
            url: http://tahiti:23403
            auth_token: '123456'
        limonero:
            url: http://limonero:23402
            auth_token: '123456'
        stand:
            url: http://stand:23404
            auth_token: '123456'
        caipirinha:
            url: http://caipirinha:23401
            auth_token: '123456'
            storage_id: 2
    config:
        tmp_dir: /tmp
    spark:
        # For more information, see http://spark.apache.org/docs/latest/configuration.html
        # spark.executor.memory: 4g
        # spark.executor.cores: 3
        # spark.cores.max: 3
        # spark.driver.memory: 4g
        # Allowed URLS:
        # local:                Run locally with 1 worker thread
        # local[k]:             Run locally with k worker threads
        # local[*]:             Run locally with as many worker threads as logical cores
        # spark://host:port:    Connect to Spark standalone cluster (default port 7077)
        # yarn:                 Connect to Yarn cluster. Cluster location will be found based
        #                       on the HADOOP_CONF_DIR or YARN_CONF_DIR variable.
        spark.master: local[*]
        spark.sql.session.timeZone: UTC

        # Required in order to connect nodes to driver.
        # In more restrictive network configuration, 
        # other ports can be configured.
        # In more restrictive network configuration, 
        # other ports can be configured.
        # spark.driver.host: your.hostname
        spark.driver.bindAddress: 0.0.0.0
        spark.port.maxRetries: 200
        spark.broadcast.factory: org.apache.spark.broadcast.HttpBroadcastFactory
        # spark.dynamicAllocation.enabled: true
        # spark.shuffle.service.enabled: true


        spark.localdir: /tmp
        spark.eventLog.enabled: false
        spark.eventLog.dir: hdfs://<namenode>:9000/path 
        spark.history.fs.logDirectory: hdfs://<namenode>:9000/path
        spark.driver.extraClassPath: "/usr/local/juicer/jars/lemonade-spark-ext-1.0-SNAPSHOT.jar:/usr/local/juicer/jars/spark-lof_2.11-1.0.jar:/usr/local/juicer/jars/spark-fairness_2.11-1.0.jar"
